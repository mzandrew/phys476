{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcc5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostly pulled from hls4ml_3.ipynb and waveform_demo.ipynb\n",
    "# last updated 2025-05-01 by mza\n",
    "name = \"mza_try1\"\n",
    "num_epochs = 100\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896e5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "import numpy as np\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7a50c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_waveforms: 10000\n",
      "time_samples: 100\n",
      "num_truths: 4\n",
      "waveforms: (10000, 100)\n",
      "truths: (10000, 4)\n",
      "scaled_waveforms: (10000, 100)\n",
      "scaled_truths: (10000, 4)\n",
      "(8000, 100)\n",
      "(8000, 4)\n",
      "(2000, 100)\n",
      "(2000, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load('waveform_data_0.npy') # (10000, 104)\n",
    "num_waveforms = len(dataset)\n",
    "training_quantity = int(0.8 * num_waveforms)\n",
    "num_truths = 4\n",
    "time_samples = len(dataset[0]) - num_truths\n",
    "print(\"num_waveforms: \" + str(num_waveforms))\n",
    "print(\"time_samples: \" + str(time_samples))\n",
    "print(\"num_truths: \" + str(num_truths))\n",
    "waveforms = dataset[:,num_truths:]\n",
    "truths = dataset[:,:num_truths]\n",
    "print(\"waveforms: \" + str(waveforms.shape))\n",
    "#print(\"waveforms[0]: \" + str(waveforms[0]))\n",
    "print(\"truths: \" + str(truths.shape))\n",
    "#print(\"truths[0]: \" + str(truths[0])) # t_peak, sigma, height, pedestal\n",
    "waveform_min = min([ min(waveforms[i]) for i in range(len(waveforms))])\n",
    "waveform_max = max([ max(waveforms[i]) for i in range(len(waveforms))])\n",
    "#print(\"waveform_max: \" + str(waveform_max))\n",
    "#print(\"waveform_min: \" + str(waveform_min))\n",
    "offset = waveform_min\n",
    "gain = 1.0 / (waveform_max - waveform_min)\n",
    "#print(\"offset: \" + str(offset))\n",
    "#print(\"gain: \" + str(gain))\n",
    "scaled_waveforms = np.array([ [ gain * (waveforms[j,i] - offset) for i in range(time_samples) ] for j in range(num_waveforms) ])\n",
    "print(\"scaled_waveforms: \" + str(scaled_waveforms.shape))\n",
    "#print(str(scaled_waveforms[0]))\n",
    "scaled_truths = np.array([ [ truths[j,0]/time_samples, truths[j,1]/time_samples, gain * (truths[j,2] - offset), gain * (truths[j,3] - offset) ] for j in range(num_waveforms) ])\n",
    "print(\"scaled_truths: \" + str(scaled_truths.shape))\n",
    "#print(str(scaled_truths[0]))\n",
    "\n",
    "train_data = scaled_waveforms[:training_quantity,:]\n",
    "print(str(train_data.shape))\n",
    "train_truth = scaled_truths[:training_quantity,:]\n",
    "print(str(train_truth.shape))\n",
    "test_data = scaled_waveforms[training_quantity:,:]\n",
    "print(str(test_data.shape))\n",
    "test_truth = scaled_truths[training_quantity:,:]\n",
    "print(str(test_truth.shape))\n",
    "#print(sample_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e482df6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Take a look at one event\n",
    "# In each row (event), the 4th column to the 103th column are 100 data points of a single waveform\n",
    "# Here we plot the first event:\n",
    "evt = 7\n",
    "x = np.zeros(time_samples)\n",
    "for i in range(time_samples):\n",
    "    x[i] = i/time_samples\n",
    "y = train_data[evt]\n",
    "plt.xlim(0, 1), plt.ylim(0, 1)\n",
    "plt.scatter(x, y)\n",
    "plt.plot([train_truth[evt][0], train_truth[evt][0]], [0.0, 1.0], color=\"green\")\n",
    "plt.plot([train_truth[evt][0]-train_truth[evt][1], train_truth[evt][0]-train_truth[evt][1]], [0.0, 1.0], color=\"green\")\n",
    "plt.plot([train_truth[evt][0]+train_truth[evt][1], train_truth[evt][0]+train_truth[evt][1]], [0.0, 1.0], color=\"green\")\n",
    "plt.plot([0.0, 1.0], [train_truth[evt][2]+train_truth[evt][3], train_truth[evt][2]+train_truth[evt][3]], color=\"green\")\n",
    "plt.plot([0.0, 1.0], [train_truth[evt][3], train_truth[evt][3]], color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4744ddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of the peak:  0.5540984344482421\n",
      "sigma of the peak:  0.07178665161132812\n",
      "height of the peak:  0.2936570646686683\n",
      "pedestal of the waveform:  0.28576807869600074\n"
     ]
    }
   ],
   "source": [
    "## The truth\n",
    "print(\"mean of the peak: \", train_truth[evt][0]) # The 0th column: mean of the Gaussian peak\n",
    "print(\"sigma of the peak: \", train_truth[evt][1]) # The 1st column: sigma of the Gaussian peak\n",
    "print(\"height of the peak: \", train_truth[evt][2]) # The 2nd column: height of the Gaussian peak\n",
    "print(\"pedestal of the waveform: \", train_truth[evt][3]) # The 3rd column: pedestal of the waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8115e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras import optimizers\n",
    "from callbacks import all_callbacks\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu, quantized_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004b7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(QDense(100, input_shape=(100,), name='fc1', kernel_quantizer=quantized_bits(16, 8, alpha=1), bias_quantizer=quantized_bits(16, 8, alpha=1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "#model.add(QDense(100, name='fc1', kernel_quantizer=quantized_bits(16, 8, alpha=1), bias_quantizer=quantized_bits(16, 8, alpha=1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "#model.add(QActivation(activation=quantized_relu(16), name='relu1'))\n",
    "model.add(QActivation(activation=quantized_sigmoid(16), name='sigmoid1'))\n",
    "#model.add(QDense(64, name='fc2', kernel_quantizer=quantized_bits(16, 8, alpha=1), bias_quantizer=quantized_bits(16, 8, alpha=1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "#model.add(QActivation(activation=quantized_relu(16), name='relu2'))\n",
    "model.add(QDense(32, name='fc3', kernel_quantizer=quantized_bits(16, 8, alpha=1), bias_quantizer=quantized_bits(16, 8, alpha=1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "#model.add(QActivation(activation=quantized_relu(16), name='relu3'))\n",
    "model.add(QActivation(activation=quantized_sigmoid(16), name='sigmoid3'))\n",
    "#model.add(QDense(24, name='fc3b', kernel_quantizer=quantized_bits(16, 8, alpha=1), bias_quantizer=quantized_bits(16, 8, alpha=1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "#model.add(QActivation(activation=quantized_relu(16), name='relu3b'))\n",
    "#model.add(QDense(16, name='fc4', kernel_quantizer=quantized_bits(16, 8, alpha=1), bias_quantizer=quantized_bits(16, 8, alpha=1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "#model.add(QActivation(activation=quantized_relu(16), name='relu4'))\n",
    "model.add(QDense(4, name='output', kernel_quantizer=quantized_bits(16, 8, alpha=1), bias_quantizer=quantized_bits(16, 8, alpha=1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='softmax', name='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "955b80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "if 0:\n",
    "    # Here, 0.1 means that 10% of the weights will be forced to be 0.\n",
    "    pruning_params = {\"pruning_schedule\": pruning_schedule.ConstantSparsity(0.1, begin_step=2000, frequency=100)}\n",
    "    model = prune.prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89858d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/build/anaconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/6 [===================>..........] - ETA: 0s - loss: 0.1557 - accuracy: 0.0865 \n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.15325, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.15325, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 1: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 1: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 3s 181ms/step - loss: 0.1552 - accuracy: 0.0840 - val_loss: 0.1532 - val_accuracy: 0.0850 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.1512 - accuracy: 0.0870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/build/anaconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 2: val_loss improved from 0.15325 to 0.14947, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.15325 to 0.14947, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 2: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 2: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1509 - accuracy: 0.0840 - val_loss: 0.1495 - val_accuracy: 0.0850 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1473 - accuracy: 0.0834\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 3: val_loss improved from 0.14947 to 0.14522, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.14947 to 0.14522, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 3: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 3: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.1470 - accuracy: 0.0840 - val_loss: 0.1452 - val_accuracy: 0.0850 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1432 - accuracy: 0.0902\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 4: val_loss improved from 0.14522 to 0.14160, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.14522 to 0.14160, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 4: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 4: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1429 - accuracy: 0.0997 - val_loss: 0.1416 - val_accuracy: 0.1745 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1400 - accuracy: 0.3418\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 5: val_loss improved from 0.14160 to 0.13901, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.14160 to 0.13901, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 5: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 5: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1398 - accuracy: 0.3698 - val_loss: 0.1390 - val_accuracy: 0.5255 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.1376 - accuracy: 0.6143\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 6: val_loss improved from 0.13901 to 0.13592, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.13901 to 0.13592, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 6: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 6: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.1373 - accuracy: 0.6660 - val_loss: 0.1359 - val_accuracy: 0.8235 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1347 - accuracy: 0.8270\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 7: val_loss improved from 0.13592 to 0.13359, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.13592 to 0.13359, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 7: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 7: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1346 - accuracy: 0.8245 - val_loss: 0.1336 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1325 - accuracy: 0.8246\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 8: val_loss improved from 0.13359 to 0.13133, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.13359 to 0.13133, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 8: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 8: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.1322 - accuracy: 0.8252 - val_loss: 0.1313 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1305 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 9: val_loss improved from 0.13133 to 0.12999, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.13133 to 0.12999, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 9: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 9: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1305 - accuracy: 0.8252 - val_loss: 0.1300 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 10: val_loss improved from 0.12999 to 0.12874, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.12999 to 0.12874, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 10: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 10: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 10: saving model to mza_try1/KERAS_check_model_epoch10.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.1293 - accuracy: 0.8252 - val_loss: 0.1287 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 11: val_loss improved from 0.12874 to 0.12764, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.12874 to 0.12764, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 11: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 11: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.1282 - accuracy: 0.8252 - val_loss: 0.1276 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1273 - accuracy: 0.8262\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 12: val_loss improved from 0.12764 to 0.12661, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.12764 to 0.12661, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 12: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 12: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1271 - accuracy: 0.8252 - val_loss: 0.1266 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1263 - accuracy: 0.8256\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 13: val_loss improved from 0.12661 to 0.12581, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.12661 to 0.12581, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 13: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 13: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1262 - accuracy: 0.8252 - val_loss: 0.1258 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1255 - accuracy: 0.8244\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 14: val_loss improved from 0.12581 to 0.12499, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.12581 to 0.12499, saving model to mza_try1/KERAS_check_best_model_weights.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 14: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.1255 - accuracy: 0.8252 - val_loss: 0.1250 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1248 - accuracy: 0.8212\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 15: val_loss improved from 0.12499 to 0.12413, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.12499 to 0.12413, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 15: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 15: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1246 - accuracy: 0.8252 - val_loss: 0.1241 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1240 - accuracy: 0.8274\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 16: val_loss improved from 0.12413 to 0.12341, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.12413 to 0.12341, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 16: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 16: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1239 - accuracy: 0.8252 - val_loss: 0.1234 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1232 - accuracy: 0.8220\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 17: val_loss improved from 0.12341 to 0.12263, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.12341 to 0.12263, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 17: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 17: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1231 - accuracy: 0.8252 - val_loss: 0.1226 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1224 - accuracy: 0.8272\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 18: val_loss improved from 0.12263 to 0.12197, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.12263 to 0.12197, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 18: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 18: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1224 - accuracy: 0.8252 - val_loss: 0.1220 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1219 - accuracy: 0.8268\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 19: val_loss improved from 0.12197 to 0.12127, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.12197 to 0.12127, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 19: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 19: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.1218 - accuracy: 0.8252 - val_loss: 0.1213 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1211 - accuracy: 0.8236\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 20: val_loss improved from 0.12127 to 0.12060, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.12127 to 0.12060, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 20: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 20: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 20: saving model to mza_try1/KERAS_check_model_epoch20.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.1211 - accuracy: 0.8252 - val_loss: 0.1206 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1205 - accuracy: 0.8194\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 21: val_loss improved from 0.12060 to 0.11999, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.12060 to 0.11999, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 21: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 21: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1205 - accuracy: 0.8252 - val_loss: 0.1200 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1200 - accuracy: 0.8266\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 22: val_loss improved from 0.11999 to 0.11935, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.11999 to 0.11935, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 22: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 22: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1198 - accuracy: 0.8252 - val_loss: 0.1194 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 23: val_loss improved from 0.11935 to 0.11871, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.11935 to 0.11871, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 23: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 23: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1192 - accuracy: 0.8252 - val_loss: 0.1187 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1186 - accuracy: 0.8268\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 24: val_loss improved from 0.11871 to 0.11805, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.11871 to 0.11805, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 24: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 24: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1185 - accuracy: 0.8252 - val_loss: 0.1181 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1180 - accuracy: 0.8286\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 25: val_loss improved from 0.11805 to 0.11743, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.11805 to 0.11743, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 25: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 25: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1179 - accuracy: 0.8252 - val_loss: 0.1174 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1173 - accuracy: 0.8236\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 26: val_loss improved from 0.11743 to 0.11680, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.11743 to 0.11680, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 26: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 26: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1173 - accuracy: 0.8252 - val_loss: 0.1168 - val_accuracy: 0.8265 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1167 - accuracy: 0.8278\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 27: val_loss improved from 0.11680 to 0.11621, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 27: val_loss improved from 0.11680 to 0.11621, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 27: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 27: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.1167 - accuracy: 0.8252 - val_loss: 0.1162 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1162 - accuracy: 0.8264\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 28: val_loss improved from 0.11621 to 0.11558, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 28: val_loss improved from 0.11621 to 0.11558, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 28: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 28: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.1161 - accuracy: 0.8252 - val_loss: 0.1156 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.1155 - accuracy: 0.8257\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 29: val_loss improved from 0.11558 to 0.11496, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 29: val_loss improved from 0.11558 to 0.11496, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 29: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 29: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.1154 - accuracy: 0.8252 - val_loss: 0.1150 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1149 - accuracy: 0.8248\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 30: val_loss improved from 0.11496 to 0.11437, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.11496 to 0.11437, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 30: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 30: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 30: saving model to mza_try1/KERAS_check_model_epoch30.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.1148 - accuracy: 0.8252 - val_loss: 0.1144 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1143 - accuracy: 0.8234\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 31: val_loss improved from 0.11437 to 0.11377, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.11437 to 0.11377, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 31: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 31: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.1143 - accuracy: 0.8252 - val_loss: 0.1138 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 32: val_loss improved from 0.11377 to 0.11316, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 32: val_loss improved from 0.11377 to 0.11316, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 32: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 32: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1137 - accuracy: 0.8252 - val_loss: 0.1132 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1131 - accuracy: 0.8248\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 33: val_loss improved from 0.11316 to 0.11257, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 33: val_loss improved from 0.11316 to 0.11257, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 33: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 33: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.1131 - accuracy: 0.8252 - val_loss: 0.1126 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.1128 - accuracy: 0.8060\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 34: val_loss improved from 0.11257 to 0.11191, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 34: val_loss improved from 0.11257 to 0.11191, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 34: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 34: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1124 - accuracy: 0.8252 - val_loss: 0.1119 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.1120 - accuracy: 0.8285\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 35: val_loss improved from 0.11191 to 0.11134, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 35: val_loss improved from 0.11191 to 0.11134, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 35: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 35: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1118 - accuracy: 0.8252 - val_loss: 0.1113 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1112 - accuracy: 0.8230\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 36: val_loss improved from 0.11134 to 0.11072, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 36: val_loss improved from 0.11134 to 0.11072, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 36: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 36: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1112 - accuracy: 0.8252 - val_loss: 0.1107 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 37: val_loss improved from 0.11072 to 0.11013, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 37: val_loss improved from 0.11072 to 0.11013, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 37: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 37: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1106 - accuracy: 0.8252 - val_loss: 0.1101 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 38: val_loss improved from 0.11013 to 0.10953, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 38: val_loss improved from 0.11013 to 0.10953, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 38: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 38: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1100 - accuracy: 0.8252 - val_loss: 0.1095 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 39: val_loss improved from 0.10953 to 0.10896, saving model to mza_try1/KERAS_check_best_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39: val_loss improved from 0.10953 to 0.10896, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 39: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 39: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1095 - accuracy: 0.8252 - val_loss: 0.1090 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1089 - accuracy: 0.8254\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 40: val_loss improved from 0.10896 to 0.10837, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 40: val_loss improved from 0.10896 to 0.10837, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 40: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 40: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 40: saving model to mza_try1/KERAS_check_model_epoch40.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1089 - accuracy: 0.8252 - val_loss: 0.1084 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 41: val_loss improved from 0.10837 to 0.10776, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 41: val_loss improved from 0.10837 to 0.10776, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 41: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 41: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1083 - accuracy: 0.8252 - val_loss: 0.1078 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1078 - accuracy: 0.8260\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 42: val_loss improved from 0.10776 to 0.10720, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 42: val_loss improved from 0.10776 to 0.10720, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 42: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 42: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1077 - accuracy: 0.8252 - val_loss: 0.1072 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1072 - accuracy: 0.8244\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 43: val_loss improved from 0.10720 to 0.10661, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 43: val_loss improved from 0.10720 to 0.10661, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 43: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 43: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.1071 - accuracy: 0.8252 - val_loss: 0.1066 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1066 - accuracy: 0.8238\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 44: val_loss improved from 0.10661 to 0.10604, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 44: val_loss improved from 0.10661 to 0.10604, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 44: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 44: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1066 - accuracy: 0.8252 - val_loss: 0.1060 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1061 - accuracy: 0.8244\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 45: val_loss improved from 0.10604 to 0.10548, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 45: val_loss improved from 0.10604 to 0.10548, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 45: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 45: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1060 - accuracy: 0.8252 - val_loss: 0.1055 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1055 - accuracy: 0.8254\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 46: val_loss improved from 0.10548 to 0.10491, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 46: val_loss improved from 0.10548 to 0.10491, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 46: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 46: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1054 - accuracy: 0.8252 - val_loss: 0.1049 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1049 - accuracy: 0.8224\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 47: val_loss improved from 0.10491 to 0.10436, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 47: val_loss improved from 0.10491 to 0.10436, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 47: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 47: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1049 - accuracy: 0.8252 - val_loss: 0.1044 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1044 - accuracy: 0.8266\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 48: val_loss improved from 0.10436 to 0.10381, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 48: val_loss improved from 0.10436 to 0.10381, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 48: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 48: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1043 - accuracy: 0.8252 - val_loss: 0.1038 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1038 - accuracy: 0.8264\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 49: val_loss improved from 0.10381 to 0.10324, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 49: val_loss improved from 0.10381 to 0.10324, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 49: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 49: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1038 - accuracy: 0.8252 - val_loss: 0.1032 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 50: val_loss improved from 0.10324 to 0.10266, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 50: val_loss improved from 0.10324 to 0.10266, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 50: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 50: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 50: saving model to mza_try1/KERAS_check_model_epoch50.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1032 - accuracy: 0.8252 - val_loss: 0.1027 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 51: val_loss improved from 0.10266 to 0.10209, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 51: val_loss improved from 0.10266 to 0.10209, saving model to mza_try1/KERAS_check_best_model_weights.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 51: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 51: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1026 - accuracy: 0.8252 - val_loss: 0.1021 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 52: val_loss improved from 0.10209 to 0.10154, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 52: val_loss improved from 0.10209 to 0.10154, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 52: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 52: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1021 - accuracy: 0.8252 - val_loss: 0.1015 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 53: val_loss improved from 0.10154 to 0.10099, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 53: val_loss improved from 0.10154 to 0.10099, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 53: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 53: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1015 - accuracy: 0.8252 - val_loss: 0.1010 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1009 - accuracy: 0.8216\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 54: val_loss improved from 0.10099 to 0.10045, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 54: val_loss improved from 0.10099 to 0.10045, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 54: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 54: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1010 - accuracy: 0.8252 - val_loss: 0.1005 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1005 - accuracy: 0.8258\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 55: val_loss improved from 0.10045 to 0.09992, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 55: val_loss improved from 0.10045 to 0.09992, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 55: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 55: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1004 - accuracy: 0.8252 - val_loss: 0.0999 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 56: val_loss improved from 0.09992 to 0.09937, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 56: val_loss improved from 0.09992 to 0.09937, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 56: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 56: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0999 - accuracy: 0.8252 - val_loss: 0.0994 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 57: val_loss improved from 0.09937 to 0.09882, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 57: val_loss improved from 0.09937 to 0.09882, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 57: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 57: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0993 - accuracy: 0.8252 - val_loss: 0.0988 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 58: val_loss improved from 0.09882 to 0.09828, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 58: val_loss improved from 0.09882 to 0.09828, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 58: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 58: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0988 - accuracy: 0.8252 - val_loss: 0.0983 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0983 - accuracy: 0.8236\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 59: val_loss improved from 0.09828 to 0.09774, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 59: val_loss improved from 0.09828 to 0.09774, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 59: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 59: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0982 - accuracy: 0.8252 - val_loss: 0.0977 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0978 - accuracy: 0.8238\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 60: val_loss improved from 0.09774 to 0.09721, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 60: val_loss improved from 0.09774 to 0.09721, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 60: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 60: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 60: saving model to mza_try1/KERAS_check_model_epoch60.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0977 - accuracy: 0.8252 - val_loss: 0.0972 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0972 - accuracy: 0.8278\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 61: val_loss improved from 0.09721 to 0.09667, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 61: val_loss improved from 0.09721 to 0.09667, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 61: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 61: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0972 - accuracy: 0.8252 - val_loss: 0.0967 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 62: val_loss improved from 0.09667 to 0.09612, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 62: val_loss improved from 0.09667 to 0.09612, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 62: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 62: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0966 - accuracy: 0.8252 - val_loss: 0.0961 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0961 - accuracy: 0.8210\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 63: val_loss improved from 0.09612 to 0.09559, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 63: val_loss improved from 0.09612 to 0.09559, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 63: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 63: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0961 - accuracy: 0.8252 - val_loss: 0.0956 - val_accuracy: 0.8265 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 64: val_loss improved from 0.09559 to 0.09505, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 64: val_loss improved from 0.09559 to 0.09505, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 64: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 64: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0956 - accuracy: 0.8252 - val_loss: 0.0950 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 65: val_loss improved from 0.09505 to 0.09453, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 65: val_loss improved from 0.09505 to 0.09453, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 65: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 65: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0950 - accuracy: 0.8252 - val_loss: 0.0945 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 66: val_loss improved from 0.09453 to 0.09400, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 66: val_loss improved from 0.09453 to 0.09400, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 66: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 66: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0945 - accuracy: 0.8252 - val_loss: 0.0940 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.0940 - accuracy: 0.8260\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 67: val_loss improved from 0.09400 to 0.09347, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 67: val_loss improved from 0.09400 to 0.09347, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 67: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 67: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0940 - accuracy: 0.8252 - val_loss: 0.0935 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.0935 - accuracy: 0.8230\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 68: val_loss improved from 0.09347 to 0.09295, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 68: val_loss improved from 0.09347 to 0.09295, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 68: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 68: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0935 - accuracy: 0.8252 - val_loss: 0.0929 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 69: val_loss improved from 0.09295 to 0.09242, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 69: val_loss improved from 0.09295 to 0.09242, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 69: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 69: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0929 - accuracy: 0.8252 - val_loss: 0.0924 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 70: val_loss improved from 0.09242 to 0.09191, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 70: val_loss improved from 0.09242 to 0.09191, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 70: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 70: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 70: saving model to mza_try1/KERAS_check_model_epoch70.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0924 - accuracy: 0.8252 - val_loss: 0.0919 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0920 - accuracy: 0.8248\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 71: val_loss improved from 0.09191 to 0.09140, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 71: val_loss improved from 0.09191 to 0.09140, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 71: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 71: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0919 - accuracy: 0.8252 - val_loss: 0.0914 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0914 - accuracy: 0.8272\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 72: val_loss improved from 0.09140 to 0.09087, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 72: val_loss improved from 0.09140 to 0.09087, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 72: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 72: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0914 - accuracy: 0.8252 - val_loss: 0.0909 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 73: val_loss improved from 0.09087 to 0.09036, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 73: val_loss improved from 0.09087 to 0.09036, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 73: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 73: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0909 - accuracy: 0.8252 - val_loss: 0.0904 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0903 - accuracy: 0.8250\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 74: val_loss improved from 0.09036 to 0.08984, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 74: val_loss improved from 0.09036 to 0.08984, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 74: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 74: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0903 - accuracy: 0.8252 - val_loss: 0.0898 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0899 - accuracy: 0.8282\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 75: val_loss improved from 0.08984 to 0.08931, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 75: val_loss improved from 0.08984 to 0.08931, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 75: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 75: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0898 - accuracy: 0.8252 - val_loss: 0.0893 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 76: val_loss improved from 0.08931 to 0.08881, saving model to mza_try1/KERAS_check_best_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76: val_loss improved from 0.08931 to 0.08881, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 76: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 76: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0893 - accuracy: 0.8252 - val_loss: 0.0888 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0889 - accuracy: 0.8262\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 77: val_loss improved from 0.08881 to 0.08830, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 77: val_loss improved from 0.08881 to 0.08830, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 77: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 77: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0888 - accuracy: 0.8252 - val_loss: 0.0883 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 78/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0883 - accuracy: 0.8246\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 78: val_loss improved from 0.08830 to 0.08778, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 78: val_loss improved from 0.08830 to 0.08778, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 78: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 78: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0883 - accuracy: 0.8252 - val_loss: 0.0878 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0878 - accuracy: 0.8244\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 79: val_loss improved from 0.08778 to 0.08727, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 79: val_loss improved from 0.08778 to 0.08727, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 79: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 79: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0878 - accuracy: 0.8252 - val_loss: 0.0873 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 80: val_loss improved from 0.08727 to 0.08677, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 80: val_loss improved from 0.08727 to 0.08677, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 80: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 80: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 80: saving model to mza_try1/KERAS_check_model_epoch80.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0873 - accuracy: 0.8252 - val_loss: 0.0868 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 81/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0869 - accuracy: 0.8206\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 81: val_loss improved from 0.08677 to 0.08627, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 81: val_loss improved from 0.08677 to 0.08627, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 81: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 81: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0868 - accuracy: 0.8252 - val_loss: 0.0863 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0863 - accuracy: 0.8256\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 82: val_loss improved from 0.08627 to 0.08578, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 82: val_loss improved from 0.08627 to 0.08578, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 82: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 82: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0863 - accuracy: 0.8252 - val_loss: 0.0858 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 83/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0858 - accuracy: 0.8232\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 83: val_loss improved from 0.08578 to 0.08528, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 83: val_loss improved from 0.08578 to 0.08528, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 83: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 83: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0858 - accuracy: 0.8252 - val_loss: 0.0853 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 84/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0854 - accuracy: 0.8206\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 84: val_loss improved from 0.08528 to 0.08479, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 84: val_loss improved from 0.08528 to 0.08479, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 84: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 84: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0853 - accuracy: 0.8252 - val_loss: 0.0848 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 85/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0848 - accuracy: 0.8262\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 85: val_loss improved from 0.08479 to 0.08430, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 85: val_loss improved from 0.08479 to 0.08430, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 85: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 85: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0848 - accuracy: 0.8252 - val_loss: 0.0843 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 86: val_loss improved from 0.08430 to 0.08381, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 86: val_loss improved from 0.08430 to 0.08381, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 86: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 86: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0843 - accuracy: 0.8252 - val_loss: 0.0838 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 87/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0838 - accuracy: 0.8236\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 87: val_loss improved from 0.08381 to 0.08331, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 87: val_loss improved from 0.08381 to 0.08331, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 87: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 87: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0838 - accuracy: 0.8252 - val_loss: 0.0833 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 88/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.0833 - accuracy: 0.8242\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 88: val_loss improved from 0.08331 to 0.08281, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 88: val_loss improved from 0.08331 to 0.08281, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 88: saving model to mza_try1/KERAS_check_model_last.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 88: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0833 - accuracy: 0.8252 - val_loss: 0.0828 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 89: val_loss improved from 0.08281 to 0.08231, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 89: val_loss improved from 0.08281 to 0.08231, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 89: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 89: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0828 - accuracy: 0.8252 - val_loss: 0.0823 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 90: val_loss improved from 0.08231 to 0.08184, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 90: val_loss improved from 0.08231 to 0.08184, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 90: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 90: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 90: saving model to mza_try1/KERAS_check_model_epoch90.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0823 - accuracy: 0.8252 - val_loss: 0.0818 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 91/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0818 - accuracy: 0.8250\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 91: val_loss improved from 0.08184 to 0.08135, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 91: val_loss improved from 0.08184 to 0.08135, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 91: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 91: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0819 - accuracy: 0.8252 - val_loss: 0.0813 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 92/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.0815 - accuracy: 0.8263\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 92: val_loss improved from 0.08135 to 0.08086, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 92: val_loss improved from 0.08135 to 0.08086, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 92: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 92: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0814 - accuracy: 0.8252 - val_loss: 0.0809 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 93/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.0811 - accuracy: 0.8238\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 93: val_loss improved from 0.08086 to 0.08038, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 93: val_loss improved from 0.08086 to 0.08038, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 93: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 93: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.0809 - accuracy: 0.8252 - val_loss: 0.0804 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 94/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0804 - accuracy: 0.8246\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 94: val_loss improved from 0.08038 to 0.07990, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 94: val_loss improved from 0.08038 to 0.07990, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 94: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 94: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0804 - accuracy: 0.8252 - val_loss: 0.0799 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 95: val_loss improved from 0.07990 to 0.07942, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 95: val_loss improved from 0.07990 to 0.07942, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 95: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 95: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0799 - accuracy: 0.8252 - val_loss: 0.0794 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 96: val_loss improved from 0.07942 to 0.07894, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 96: val_loss improved from 0.07942 to 0.07894, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 96: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 96: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0794 - accuracy: 0.8252 - val_loss: 0.0789 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 97/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0790 - accuracy: 0.8226\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 97: val_loss improved from 0.07894 to 0.07846, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 97: val_loss improved from 0.07894 to 0.07846, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 97: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 97: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0790 - accuracy: 0.8252 - val_loss: 0.0785 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 98: val_loss improved from 0.07846 to 0.07800, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 98: val_loss improved from 0.07846 to 0.07800, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 98: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 98: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0785 - accuracy: 0.8252 - val_loss: 0.0780 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 99: val_loss improved from 0.07800 to 0.07753, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 99: val_loss improved from 0.07800 to 0.07753, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 99: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 99: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0780 - accuracy: 0.8252 - val_loss: 0.0775 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
      "Epoch 100/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0776 - accuracy: 0.8252\n",
      "***callbacks***\n",
      "saving losses to mza_try1/losses.log\n",
      "\n",
      "Epoch 100: val_loss improved from 0.07753 to 0.07706, saving model to mza_try1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 100: val_loss improved from 0.07753 to 0.07706, saving model to mza_try1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 100: saving model to mza_try1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 100: saving model to mza_try1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 100: saving model to mza_try1/KERAS_check_model_epoch100.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0776 - accuracy: 0.8252 - val_loss: 0.0771 - val_accuracy: 0.8265 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "if train:\n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    #optimizer = optimizers.SGD(learning_rate=0.1)\n",
    "    #model.compile(optimizer=optimizer, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    model.compile(optimizer=optimizer, loss=['mse'], metrics=['accuracy'])\n",
    "    callbacks = all_callbacks(\n",
    "        stop_patience=1000,\n",
    "        lr_factor=0.5,\n",
    "        lr_patience=10,\n",
    "        lr_epsilon=0.000001,\n",
    "        lr_cooldown=2,\n",
    "        lr_minimum=0.0000001,\n",
    "        outputDir=name,\n",
    "    )\n",
    "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        train_truth,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.25,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks.callbacks,\n",
    "    )\n",
    "    loss, acc = model.evaluate(test_data, test_truth, verbose=0)\n",
    "    model = strip_pruning(model)\n",
    "    model.save(name + '/KERAS_check_best_model.keras')\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    model = load_model(name + '/KERAS_check_best_model.keras', custom_objects=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9bc6f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.821, test_loss: 0.077\n",
      "63/63 [==============================] - 1s 2ms/step\n",
      "[0.4807621  0.04073853 0.25706863 0.22143087] : [0.54149693 0.09774141 0.22505841 0.20915764]\n"
     ]
    }
   ],
   "source": [
    "print('test_acc: {:.3f}, test_loss: {:.3f}'.format(acc, loss))\n",
    "y_keras = model.predict(test_data)\n",
    "print(str(y_keras[0]) + \" : \" + str(test_truth[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50f7ec65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGiCAYAAADA0E3hAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAANwJJREFUeJzt3X10VPWB//HPEE0i1OADGMiDTbVapVWwsGQjRaW/bDnVRTiUlQUKlK1YK+xR0m2FgkTWCqxVSluxrFpqzwryYKP1JxRXKTlapYdTHs6xxYcfBRYMJEBZiI6aQPj+/hgmj/Nw78y9M/Odeb/OmZPk5s7c78ydufcz3/t9CBhjjAAAACzQK90FAAAAcIrgAgAArEFwAQAA1iC4AAAAaxBcAACANQguAADAGgQXAABgDYILAACwBsEFAABYg+ACAACs4Tq4vP766xozZoxKSkoUCAT04osvxr1PfX29vvzlL6ugoECf//zn9cwzzyRQVAAAkOtcB5dgMKjBgwdrxYoVjtbfv3+/brvtNo0aNUq7d+/WfffdpzvvvFOvvPKK68ICAIDcFkhmksVAIKAXXnhB48aNi7rO/fffr40bN+rPf/5z+7J//ud/1smTJ7V58+ZENw0AAHLQeX5vYNu2baquru6ybPTo0brvvvui3qelpUUtLS3tf589e1YnTpzQpZdeqkAg4FdRAQCAh4wx+vDDD1VSUqJevbxpVut7cGlsbFRxcXGXZcXFxWpubtYnn3yiCy64oMd9lixZokWLFvldNAAAkAKHDh1SWVmZJ4/le3BJxLx581RTU9P+96lTp3T55Zfr0KFDKioqSmPJkAmCrUGVPFYiSTr8vcPqk98nzSWKL26Zg0GpJPR/HT4s9fHgOSXxmDHL60dZAWSl5uZmlZeX68ILL/TsMX0PLgMGDFBTU1OXZU1NTSoqKopY2yJJBQUFKigo6LG8qKiI4ALlteZJhaHfi4qKrAguccucl9fxe1GRN2EgiceMWV4/ygogq3nZzMP3cVyqqqq0ZcuWLsteffVVVVVV+b1pAACQZVwHl48++ki7d+/W7t27JYW6O+/evVsHDx6UFLrMM23atPb17777bu3bt08/+MEP9O677+qJJ57Q+vXrNWfOHG+eAQAAyBmug8uf/vQn3XDDDbrhhhskSTU1Nbrhhhu0cOFCSdKRI0faQ4wkfe5zn9PGjRv16quvavDgwXrsscf09NNPa/To0R49BQAAkCtct3G55ZZbFGvol0ij4t5yyy3atWuX200BAAB0wVxFAADAGgQXAABgDYILAACwBsEFAABYg+ACAACsQXABAADWILgAAABrEFwAAIA1CC4AAMAaBBcAAGANggsAALAGwQUAAFiD4AIAAKxBcAEAANYguAAAAGsQXAAAgDUILgAAwBoEFwAAYA2CCwAAsAbBBQAAWIPgAgAArEFwAQAA1iC4AAAAaxBcAACANQguAADAGgQXAABgDYILAACwBsEFAABYg+ACAACsQXABAADWILgAAABrEFwAAIA1CC4AAMAaBBcAAGANggsAALAGwQUAAFiD4AIAAKxBcAEAANYguAAAAGsQXAAAgDUILgAAwBoEFwAAYA2CCwAAsAbBBQAAWIPgAgAArEFwAQAA1iC4AAAAaxBcAACANQguAADAGgQXAABgDYILAACwBsEFAABYg+ACAACsQXABAADWILgAAABrEFwAAIA1CC4AAMAaBBcAAGANggsAALAGwQUAAFiD4AIAAKxBcAEAANYguAAAAGskFFxWrFihiooKFRYWqrKyUtu3b4+5/vLly/WFL3xBF1xwgcrLyzVnzhx9+umnCRUYAADkLtfBZd26daqpqVFtba127typwYMHa/To0Tp69GjE9desWaO5c+eqtrZW77zzjn75y19q3bp1+uEPf5h04QEAQG5xHVyWLVummTNnasaMGRo0aJBWrlyp3r17a9WqVRHXf+uttzRixAhNnjxZFRUV+trXvqZJkybFraUBAADozlVwaW1t1Y4dO1RdXd3xAL16qbq6Wtu2bYt4nxtvvFE7duxoDyr79u3Tpk2bdOutt0bdTktLi5qbm7vcAAAAznOz8vHjx9XW1qbi4uIuy4uLi/Xuu+9GvM/kyZN1/PhxfeUrX5ExRmfOnNHdd98d81LRkiVLtGjRIjdFAwAAOcD3XkX19fVavHixnnjiCe3cuVN1dXXauHGjHnrooaj3mTdvnk6dOtV+O3TokN/FBAAAFnBV49KvXz/l5eWpqampy/KmpiYNGDAg4n0eeOABTZ06VXfeeack6brrrlMwGNRdd92l+fPnq1evntmpoKBABQUFbooGZIy2NumNN6QjR6SBA6WRI9NdIgDIHq5qXPLz8zV06FBt2bKlfdnZs2e1ZcsWVVVVRbzPxx9/3COc5OXlSZKMMW7LC2S0ujqpokIaNUqaPDn0s6JC+u1L6S4ZAGQHVzUuklRTU6Pp06dr2LBhGj58uJYvX65gMKgZM2ZIkqZNm6bS0lItWbJEkjRmzBgtW7ZMN9xwgyorK7V371498MADGjNmTHuAAbJBXZ00YYLUPY83NEhTpkhiBAAASJrr4DJx4kQdO3ZMCxcuVGNjo4YMGaLNmze3N9g9ePBglxqWBQsWKBAIaMGCBWpoaFD//v01ZswYPfzww949CyDN2tqke+/tGVqkyMsAAIlxHVwkafbs2Zo9e3bE/9XX13fdwHnnqba2VrW1tYlsCrDCG29IH3wQYwXCCwB4grmKAA8cOZLuEgBAbiC4AB4YODDdJQCA3EBwATwwcqRUViYFAlFWiLYcAOAKwQXwQF6e9NOfhn7vHl6ihhkAgGsEF8Aj48dLzz8vlZZ2XV5WJq1enZ4yAUC2SahXEYDIxo+Xxo7tOXLup22S/pLu0gGA/awKLsHWoPJaGbQu1wVbgxF/zyR/d2PH75+2OShza1A6P8LvyUjiMWOW14+yAshKfhyjA8aCcfebm5vVt29faa6kwnSXBgAAOPKppKXSqVOnVFRU5MlD0sYFAABYw6oal8PHDnuW2GCvYGtQxY+Fppho+l6T+uT3SXOJ4otb5mBQOjdthpqapD4ePKckHjNmef0oK4Cs1NzcrJL+JZ7WuFjVxqVPfh8rTlJIHRvfExHLfPrcTZLy+4RuyfLoMXuU14+yAshKbfltnj8ml4oAAIA1CC4AAMAaBBcAAGANq9q4ANmkra1joLrSi6Sb0l0gALAAwQVIg7o66d57pQ8+CP3dW1J4mKbXX5caTnaMupvHmIsA0I7gAqRAW6eG9UuWSIsXSdEGIvj6rdLH534vKwtN3jh+vO9FBAAr0MYF8FldnXTtoI6/H344emjprqFBmjAh9BgAAIIL4Ku6ulDwONyQ2P3DAee++7rW2gBAriK4AD5pawu1Y0l2bGpjpEOHQg15ASDXEVwAn7zxRkfjWy8cOeLdYwGArQgugE+8DhoDB3r7eABgI3oVAT7xKmgEAqHeRSNHevN4AGAzgguQhM6DyHUfd2XkyFDgaGiQEm3mEgiEfi5fznguACARXICY4SOW7oPISV3HXcnLC/0+YYKkQNf7BgKhRreLFklXXRUaOVe39txGWVkotDCOCwCEEFyQ0+KFj1j3mzChZ4+h8Lgrzz8fuv/48aHf//V70uFO6/UIJMGO//1uEyPnAkA0NM5FzgqHj+49f+IN+harm3OkcVfGj5fe2dOxzqbfSfv3Rw9GN90kTZok3XILoQUAuiO4ICe5DR+dxevmHGnclc4B5CZqUQAgYQQX5KREwkeY027OjLsCAN6jjQtyUiLhI9yId8+e6Ot3xrgrAOA9ggtyktNQEV4vUiPeaBh3BQD8Q3BBTuoyxkqEdi6dw0e0HkSRMO4KAPiLNi7ISeExVqSOsBHWOXxI7iZKLCvr6ArtlbY2qb5eeu650E9miQaQywguyFnhMVZKS7su7xw+nE6UuGCBtHVr7G7OiairkyoqpFGjpMmTQz8rKqJ31QaAbMelIuS08eOlsWOjj5zrtBHvoEGhcVe85HSQOwDIJQQX5Ly8vOihw20jXq/EG2cmEAiNMzN2LG1pAOQWLhUBMYQb8XZvBxMWCEjl5d73IEpmnBkAyGYEFyCCcIPY9eulmTNDy2I14vW61oNB7gAgMi4VAd1EGrPl0ktDP//2t45lfs7cnK5LVACQ6QguQCfRGsSeOBFatmiRdNVV/s/c7GacGQDIJQQX4BwnDWKffjrU5dnvBrHhcWYmTAhtt3OZGOQOQC6jjQtwTqY1iHUyzgwA5BpqXIBzMrFBbLRxZqRQ4+FIY88AQDYjuADnZGqD2O7jzERqPFxWFrq0RC0MgGzHpSLgnHSN2eJGuPFw90ta4dF0mQoAQLYjuADnOJ14MV2XZOI1HpZCo+kyCSOAbEZwATrJ5AaxmdZ4GADSgTYuQDfxJl5Ml0xsPAwAqUZwASKINfFiuiTTeHj9eumyz2VGAAOAZHCpCLCE28bDv/1tx/9m/Is0apRUUUEDXgB2I7gg54QnUHzuudBPWxqzumk8XFcnTZnS8zHofQTAdgQX5JS6ulCtw6hR0uTJ9tVCOGk83N77KML96X0EwHYEF+SMbBkDZfx46cABaetWac2a0M/9+zt6PNH7CEA2o3EucoKTCRTvuy/Um8iGxquxGg/T+whANqPGBTkhl2ohMnXqAgDwAsEFOSGXaiHaex9F+X8mTF0AAIkiuCAn5EItRLi31Pr10syZkdfJhKkLACAZtHFBTgjXQjQ0RG7nEgiE/m9rLUSkGaPLL5F0out6ZWWh0MIs0gBsRXBBTgiPgTJhQiikdA4vttdChHtLdQ9kJzqFll+tYuRcANmBS0XIGZk8gWKiYvaW6vT7N74R6oVEaAFgO2pckFMydQLFRMXrLRX25pvSTV/3vzwA4DeCC3JOJk6gmCinvaAaG/0tBwCkCpeKAIs57QU1YIC/5QCAVEkouKxYsUIVFRUqLCxUZWWltm/fHnP9kydPatasWRo4cKAKCgp09dVXa9OmTQkVGECHeDNGh40YkZryAIDfXAeXdevWqaamRrW1tdq5c6cGDx6s0aNH6+jRoxHXb21t1T/8wz/owIEDev755/Xee+/pqaeeUmn3FpIAXIs5Y3S39QAgG7gOLsuWLdPMmTM1Y8YMDRo0SCtXrlTv3r21atWqiOuvWrVKJ06c0IsvvqgRI0aooqJCN998swYPHpx04QFE7y3FdwMA2chVcGltbdWOHTtUXV3d8QC9eqm6ulrbtm2LeJ+XXnpJVVVVmjVrloqLi/WlL31JixcvVltbW9TttLS0qLm5ucsNQHSRZozesyfdpQIA77nqVXT8+HG1tbWpuLi4y/Li4mK9++67Ee+zb98+/f73v9eUKVO0adMm7d27V/fcc49Onz6t2traiPdZsmSJFi1a5KZoQM7r0VsqmK6SAIB/fO9VdPbsWV122WV68sknNXToUE2cOFHz58/XypUro95n3rx5OnXqVPvt0KFDfhcTAABYwFWNS79+/ZSXl6empqYuy5uamjQgSn/LgQMH6vzzz1dep9aB1157rRobG9Xa2qr8/Pwe9ykoKFBBQYGbogEAgBzgqsYlPz9fQ4cO1ZYtW9qXnT17Vlu2bFFVVVXE+4wYMUJ79+7V2bNn25e9//77GjhwYMTQAngpPGPyc8+FfsZoWgUAsIDrS0U1NTV66qmn9Otf/1rvvPOOvvvd7yoYDGrGjBmSpGnTpmnevHnt63/3u9/ViRMndO+99+r999/Xxo0btXjxYs2aNcu7ZwFEUFcnVVRIo0ZJkyeHflZUhJYDAOzkesj/iRMn6tixY1q4cKEaGxs1ZMgQbd68ub3B7sGDB9WrV0ceKi8v1yuvvKI5c+bo+uuvV2lpqe69917df//93j0LoJtoMyY3NISW2zqpIgDkuoTmKpo9e7Zmz54d8X/19fU9llVVVemPf/xjIpsCXIs5Y7IJDdR2332hyRYZmA0A7MJcRcg68WZMNkY6dCi0HgDALgQXZB2nMyY7XQ8AkDkILsg6TmdMdroeACBzEFyQdeLNmBwISOXlofUAAHYhuCBrhMdsWb9emjkztKzHjMnn/l6+nIa5AGCjhHoVAZmmri7Uk6hzo9xLLw39/NvfOpaVlYVCC12hAcBOBBdYL9qYLSdOhJYtWiRddVWoTcvIkdS0AIDNCC6wmpMxW55+Wtq/n8AS1tYW6gp+5AhhDoB9aOMCq735FmO2uME0CABsR3CB1Robna3HmC0dl9S6B73wNAiEFwA2ILjAagMGOFsv18dsiXdJTQpNg8Ds2QAyHcEFVhtxI2O2OPHmm1xSA5AdCC6wWl6e9NOfhn5nzJbouKQGIFsQXGC98eOl55+XSku7Li8rCy1nzJbkLqmt3xAa2I/LSAAygV3doYNBvjpDag12/B4MSqel8aOlsX8JXRJpbAydqEeMOPd2CUZ9pNSJUOYugsHIvyej0+OMGBLUVSXS4cNShGYuCigU/EZ+WVJQevmFjvvOmhFU4LRUWiL9+MfS2GofygogO/lwjLAruJSUpLsEyATnS5p/7vfi4vYQkCfppjQVKa4oZY6ouNjzzeeVFOv9eCs1SOob+vUfO5X3mIrVR5IOS5rS7T4+lBUAYuFSEQAAsIZdNS6HD0tFRekuBdKtNSj97Nw3/aYmKb9PesvjRLwyB4MdtRdNTVIfD55TlMdsa4tySU3S669LX79VMgpKCt23v5oUUEd5eiuoY/K4rACyU3Oz51dL7AouffpwkETosktYnz52BBc3Zfbjfd7pMfMk3fT1yKs1nJQ+7rbsE/WRFKU8fCYBxOJDq34uFQFol+sD9QHIfAQXAO1Gjgx1I1eMAf3KSiP/DwBSgeACoF3nAf26Cw/o98gjqSsPAHRHcAHQxfjx0urVPZeHB/QbOzb1ZQKAMLsa5wJIibG3S/pL6PdVv5I+Vxq6jJQxA/oByFkEFwBqawtNsHjkSKiB7pcrO/53xz9JffLTVzYA6IzgAuS4ujrp3nu7zh5dUiHpW2kqEADEQHABclhdnTRhgmS6TWB0+HB6ygMA8RBckPFiXcZA4traQjUt3UOLpC4zMTIrNIBMQnBBRuMyhn/eeKPr6xrNm29JX/8//pcHAJygOzQyVvgyRveTK5cxvHHkiLP1Ghs7fm9rC81n1PlvAEglggsyktPLGGvXSfX1nEAT4XR4/wEDQj/r6qSKitAkjGHXXhtaDgCpQnBBRnJ6GePOb0ujRoVOqJxA3QkP7x+IMrx/2IgbY9d+TZjAaw8gdQguyEhOL2OENTRwAnWr8/D+PcJLt7+j1X6FF913H7VeAFKD4IKM5HaW4vBJlROoO+PHh4bxL+02cWLnv998K3btlzHSoUOhWjIA8BvBBRnJ6WWMzjiBJmb8eOnAAWnrVmnNmtDPPX/p+H/nxrmxuK0lA4BE0B0aadN9fJb2uXDUcRljwoRQeInYSDcKTqDu5eVJt9zS8XewteP3cOPceNzWkgFAIqhxQVqEe6iMGiVNnhy5gW20yxjxcAL11ogbY9d+BQJSeXkoeAKA3wguSLloPVQiNbDtfBnj2Wel/v3Vo+FoGCdQf8RqxBv+c/nyjtoyAPATwQUpFWt8lmgNbMOXMaZMkVaujPy44RMqJ1B/xGrE+/zzof8DQCoQXJBS8cZnidfAdvx4afXqnsvLyjiB+i1c+/W7TR3L9uzhNQeQWjTORUo5bTgba72xt0s61+tl1a+kz5V2bdgL/+TlSTfd1PVvAEglggtSymnDWafr3fFPUp/8xMsDALALl4qQUvHGZ6GBLQAgFoILUipmDxUa2AIA4iC4IOWi9VApK5PWrZMuuUR67jlmfQYA9EQbF6TF+PHS2LFdR849flyaM6drr6OyslANDT1XAAASNS5Io/D4LJMmSSdOSHfc4WxQOgBA7iK4IO0SGZQOAJCbCC5Iu2QHpUPmaWsLtVGirRIAr9HGBWnnxaB0yBx1daEaNNoqAfADNS5IO68HpUP6uJlAEwASQXBB2jEond3Cl4VWr5buvpu2SgD8RXBB2jEonb1++1upokIaNUr65jelY8eir0tbJQBeILggI8QalI5ZnzPXlCmxG1ZHQlslAMmgcS4yRqRB6Zj1ObNFuCoUl59tldraeP8A2Y7ggowSHpQO2ScQCNWg+dVWKZt7MxHIgA4ElxyTrgMgB97c5ndbpXBvpu4Ng8O9mWy+3JjNgQxIRNa0cUnHgFe2DbJVV9fRkHLy5NDPigr/u6ima7vIHH62VcrmkZdt6V5u27EQdsuKGpd0fCNJ1Ta9qqnw6xtpvPJl8zdhSFF6sEuS+veXfvKTUINrP2vY3Iy8nGmXIWN9fuIFskAgFMjGjk1v7WWm1QhRu5sDjAVOnTplJJlTp071+N9vfmNMIGBM6KPccQsEQrff/Mb78qRqm7/5jTFlZV23UVbm/vHPnOn5ON3LXV4eWs+L8q1fb8zWrcY8+6wx/ft7v92PWj4yelBGD8p81PKRuzunSdwyf/RRxwvzkUfPKYnHjFneTo/bRx/1+Cz4+dnr7MyZ0Pts9uzo77HOtzVr/C2PW/E+31u3OnteW7f6V8bwa7xmTehn989qOo6/sXh1zMw28fajn2KdvxNldXDx64QcS6q26eUBwY8DYLTyJXJze+AluDjdqP/B5cXVH/X4PJSXO39/JnpAjXSCSucJ3i0nn+81a9IbyOKFgFQff20LUZki3WGO4NLtiafjG0kqtun1AcHrA2C88rm9uT3wElycbtT/4GI++sjT8OHkgOo2NPvxBSYZTj/fr72WvkDmJASk8vibaSHKFpkQ5vwILlY3zk3H5Hyp2KbXsyU7HTdjzx5nDevilc8t5iCyW7gL+6RJoZ9O2hMk2ug0VruPSDJx5GWnn28pPVNhxGtbY0xoaocNG5w9XrLHXyfvFWaY7ymbG60nFFxWrFihiooKFRYWqrKyUtu3b3d0v7Vr1yoQCGjcuHGJbLaHdEzOl4pteh2O4s0FFPajHznr8eNVEGQOotyUzAHVbWjOxJGXnX5+jh5Nz1QYTl7jY8ekJ55w9njJHAudvlcaGpw9Xi6N2pzNYc51cFm3bp1qampUW1urnTt3avDgwRo9erSOHj0a834HDhzQv/3bv2mkh2epdEzOl4pteh2OYs0FFEm8b71eBMFM/CaM1EjmgOr0xDN7trR1q7R/f+Khxa8uvm4+3+mYCiOTvpg4fa/EmiOrs1yq3U3HFYlUcR1cli1bppkzZ2rGjBkaNGiQVq5cqd69e2vVqlVR79PW1qYpU6Zo0aJFuuKKK+Juo6WlRc3NzV1ukaRjcr5UbNOPcBTtABhJvG+9TmtwYsnEb8JIjUQOqOEQsWePs/t+4xvOL1tF4ufYQ24/3+PHSwcOhILYmjXJB7J4/Pxi4jYMOn2v9O/PDPPdpfqKRErH8nHTIKalpcXk5eWZF154ocvyadOmmdtvvz3q/RYuXGjGjRtnjDFm+vTpZuzYsTG3U1tbayT1uEVr3BOp4Zabng2J8Hub4UZVXnc1DTekXLAguYZ10coX69a/f6iLdLLd8Wic63SjqWmc65bbRp1uehA5aYSZit4pTreRrq7ksYQbuibTa7C8vGNYhPBrsGGD+8bYbt4ryb6m6ewy7Id4+9HLBsuxGk+nvVdRQ0ODkWTeeuutLsu///3vm+HDh0e8zxtvvGFKS0vNsWPHjDHOgsunn35qTp061X47dOhQ3Ceejjed39tMNhzFKp8XPY2cnlC8PhgTXJxuNDODi5sDqpseRE7eZ6noneK0t1Q6vnA5lcgXEyk0pk60kJLIPnN78k30NU13l2G/uA1ziZzT4gX9//ovy4JLc3OzqaioMJs2bWpf5iS4dOdHYoslk5K3X11NverK2L18kQ5YXh+MCS5ON5pZwaXze2XRovgHVLfd7uO9z7zs4rtggTe1NZl0rOku0bFyvO6u7vfJN5X7zOl9vXxfOA1ziYQ3J0G/tDTNwcXtpaJdu3YZSSYvL6/9FggETCAQMHl5eWbv3r2OtptocEk0PdqevJ18EP2sRvT7YExwcbrRzAkukT5Xl14aukU7oCYbIjpzWpPy7LPuTtQ2jCUS6fPo9gQaHgU73vGipSXxMZ5ifUnyq3bK7T5L5vyQTE1csucgvy6POvuMZsAAdMOHDzezZ89u/7utrc2UlpaaJUuW9Fj3k08+MW+//XaX29ixY81Xv/pV8/bbb5uWlhZH20wkuMQbjj7SDsyEwXqS5eaDmIpqRD8QXJxuNDOCS6zPlRSqffHrcmaY0xD0k5+4O9mma0A2p5wGRjcD/8U6Xjh9DRLZj34cfxJpQ+P2fdz5tYt3bknHOchJzWa09onOPqMZEFzWrl1rCgoKzDPPPGP27Nlj7rrrLnPRRReZxsZGY4wxU6dONXPnzo16/1RcKnJTVRn+wGbqtyW3vGj46FU1ol8ILk43mv7gksznyssg4DQEPfus+4apbmtrUjVnktftg8KPGet44fR1TnQ/es3t+8Lpc0mkJi5ebVWkz4oXYc5t2HTf5MD74OJ6duiJEyfq2LFjWrhwoRobGzVkyBBt3rxZxcXFkqSDBw+qV6/0DcjrdmTN8JglDz7ozQyz6Z6Z1G1X0/HjQ7PLMsMz/JDMzM3hbsMNDZE/z4FA6P9Ourg67fJZWhoa7mDChNDjOzmOhJ9DJo0l4vY4aIyz2abjHS8SeW5u9qPXnJb32DF3Ax92PjZecomzz8ATT7j7rHg1K7fbcVw6P7exY+N/RktKnA8Q6JhnEchHbmpcEqmqDASMueQSZ+uGW81HSraJXJ7ymteNbv2a4TkZ1Lg43Wj6a1ySvdzjVbdhL3qnxLvFq61J5WclmUs2Xsyz5nVNj1+cvi/ctn1K5L5OZzmfPbujcbsXr2ei50ynTQ786FVk9VxFkSQyCqAx0okTztZ9/PHIg1FFm0/jgw+kO+7wZyCrzsKD/zQ0hAZjSmYgps6Db33zm7G/SRpj77DR8F+yg2B5NXKs24EjOw/6tmCBs22Ea2uibcMY6c47pfXrYw/Q5cVAXsmMhprMfd2O0p3sQJTJvlZO3xdOBu7sLnxsdFoTd+WVztZ7/HGptjb0+JG2KbmbgyiRAUU7H/fjfUZvv93547ooQOYL17i8/PKpuC3ik/mmcckliX1TcNtt0+tvGV6Op+K2K2P4lqrr9sZQ4+J8o+mvcfGq95pXDTMT6Z3iRW2N0waxXrUlS1eNS6znEWlQOq+7+Sba7i7e+yKZQfmc1sSF27gkso1INye97To//2TG7Yl1XvZjOJOAMcb4kIc81dzcrL59+0rnHdYllxZJ6lpDUlIq/fjH0tjbQynz2kHS4cOSXD6z+fOlhxef+8PJfQOhlLlypTTmH91tK3zfPX9Jrg3Mb1+SpkyRo/KWlkmPPBJ6nSJpf+0SuB656XfSTSm6Rh1sDar4sVCbqqbvNalPfp/UbDgJccscDErn2ompqUnq48FzSuIxY5bX5eO2v0elru/Tc9/wVq+O/p70Q1ub9OZbUmOjNGCANOLG+J9Bt8+h8zb+uvfccaX7Z7TbfaN+lhN4nRI6Dnp0TOpcBrevs1NevlZh8cob9T0Qxw/ul84/L8q5Jdp7wOU2Yul8fozlty9J3/9+Ysf/WNtobm5WSf8SnTp1SkVFRe4fPAK7gstcSYXpLg0AAHDkU0lL5Wlwybo2LgAAIHvZVeNy3mEpEDuxdb5k0b3q729/k+6/v2tVWKzLJ6+/Id369fjl+78vS9/5TmKXp9olUMW5foP0LzPir7fqV9Id/xR/PafPNyzepSe/cKnI6UYz41JRuvhxOcEtp5/R73xH+s//jL+e089yZ5EugUj+Xcbxm9fHvUjcvHdcXWJxeTnO7TE5HreX9BO5fNR9G35cKpJnrWV8FG7cExrIJrlGom4a+SUyGVwyDavcdpf0eqROJw3QvJrhORk0znW60fQ3zk2EFw1xM2VASa9H7E3HIG2Zxu8RihN574TfswsWpP6Y7OaWSCeK8HNz2l27+zb8aJybdZeK4nW/zMsLDd4zaVLoZ6zU66YLZbQuYW4Y465rcbxubE66PncW7/kGAqGGyFOmxH/tgER07oqfzPABbga+k7zpghyJ08/oPfd4+1m2Xaz94fVxrzu37x2p47wyaJCzbTjtcu7kHLRokfMu+4kMEBh+bt/4hn/bcCtrgotfH2w340h0HvthzZrQzw0bQuu64eWbuvPYFE54NW4G4Fa0sZDCI3W6CS9uRpD2KixF4vQzmp/v/WfZVvH2hx/Hvc7cjj7eWbLjFkUS65j8m99ICxeGRn73O/j6HRhd8azuxkfxLhWlYvRFL6Yy97oaMcyPmVMzZULFSLhU5HSj9lwq8vrSjtPLCV6OQBpLMnOCeTELsi3cTDLo12uVzKUor8YtisTpDM9+TpqbyEjWflwqsi64RBrIyZaTtJ9tSDI5aHiN4OJ0o/YEl1S31woEQv9PZTsYp5/RXPosd5ZM2xIvX6tkw4dX01QkIhWT5roNjDkfXJyMnOtWqmc9dtOIN12zL2c6govTjdoTXJKd0yiSeCeQRYu8DUtIjt+Nbt1INnyks+bMac1MpEDmNFi5OQf7EVxczw6dTp1nIY01Q7NT6Zj1OHy9svusnpEw+zJyhZ9tAyLNoLt8udTS4uxxkpm7x0/pnonea8m0LfFavPdOvONxvFm0/RRuTBtJrFnDjXE2Q3i8baSCVcHFS17twER0flM3NEhz5kSeiCtaObLtgAWEG/41NET+TAYCof+7bfgX6wRSX+/sMVLRS8KturrIJ9Wf/jS5CQvTeVzxI7wmI9nwke6TeyRuekxlWtk7y9ngku4dGH5T19c7n335llv8OWAB6RbuKTJhQsdMymHJ9hSJdgLxKyz5zY+a4kw4rvi1P5IJZKkIH6kMjJlUq5WMrOkO7Vam7EC33Ta96i4KZJpUd8X3u1utH+LVFBsj3X13aGRXp+PRpPu4Eh6zZf16aebM0DKv9oefXd29kOryZVqtVsI8ay3jIz8a92RKQzCn5XjttcwYCTQT0DjX6UbtaZzbWap71STbkDKV5XV6vHDawD/dIwxHeu296jkaqxGqFGqcnc6eW140knXLz+7a0eR8ryIvn3g6dmAy5XjttcwIWpmA4OJ0o3YGl3RINHykulei095XTk+C6fwC52ewiBfI3AY8r6UzMKa6uzZD/nsoU6qJnZbj6FFnj5fp1yaBTORmKpCwdFxicVuFb0zo5333Rb5slK5L5k46Rzz9tHTHHYlNLxKvDWN3qb7cnsi0Al7JhtHRcza4SJmzA52UI2uuTQJZIN6JV4oeFpIRb9j1SGKdBNN1XPH7xO02aPm5zyJJdxvLSNPT7N9vR2iRcrhXUVg6+9u7KYetPSCAbJSuXomxel/FE+kkmK7jit8n7kSCll/7LJJM+CKaid21ncrpGpewRKqJU12OTLm0BSC935gTnYk+0kkwXccVv0/cidRMhaXicntGTVhoIYKLRTLl0haQ69L9jblzVf+zz0r9+yd+EkzHccXvE3esQBZPKi6380U0OQQXy9h+bRLIBpnwjTlcQztlirRyZcd2u5dDin8STPVxJRUnbrc1U6mu5eCLaOJyvo2LjWy+NglkAz9H+k1EsnPrSKk/rnhRZifb6Nx28P/9P+nBB0P/S/c+i1Q+pnBxhuACAAlIxYnXbXlsOwmmoszdA9mXvpQ5+0zii2giCC4AkKBMCws2ngTTUdOTSfsM7hFcACAJNoaFXMc+sxuNcwEAgDUILgAAwBoEFwAAYA272rgEg7SggtQa7Pg9GJROp68ojsUrczAY+fdkJPOYscrrR1kBZCcfjhF2BZeSknSXAJngfEnzz/1eXGxHcHFT5uJi77fv9jGdltePsgJADFwqAgAA1rCrxuXwYamoKN2lQLq1BqWfnfum39Qk5fdJb3mciFfmYLCj9qKpSerjwXNK5jFjldePsgLITs3Nnl8tsSu49OnDQRKhyxhhffrYEVzclNmP97nbx3RaXj6TAGJpa/P8IblUBAAArEFwAQAA1iC4AAAAaxBcAACANQguAADAGgQXAABgDYILAACwBsEFAABYg+ACAACsQXABAADWILgAAABrEFwAAIA1CC4AAMAaBBcAAGANggsAALAGwQUAAFiD4AIAAKxBcAEAANYguAAAAGsQXAAAgDUILgAAwBoEFwAAYA2CCwAAsAbBBQAAWIPgAgAArEFwAQAA1iC4AAAAayQUXFasWKGKigoVFhaqsrJS27dvj7ruU089pZEjR+riiy/WxRdfrOrq6pjrAwAAROM6uKxbt041NTWqra3Vzp07NXjwYI0ePVpHjx6NuH59fb0mTZqkrVu3atu2bSovL9fXvvY1NTQ0JF14AACQW1wHl2XLlmnmzJmaMWOGBg0apJUrV6p3795atWpVxPVXr16te+65R0OGDNE111yjp59+WmfPntWWLVuibqOlpUXNzc1dbgAAAK6CS2trq3bs2KHq6uqOB+jVS9XV1dq2bZujx/j44491+vRpXXLJJVHXWbJkifr27dt+Ky8vd1NMAACQpVwFl+PHj6utrU3FxcVdlhcXF6uxsdHRY9x///0qKSnpEn66mzdvnk6dOtV+O3TokJtiAgCALHVeKje2dOlSrV27VvX19SosLIy6XkFBgQoKClJYMgAAYANXwaVfv37Ky8tTU1NTl+VNTU0aMGBAzPs++uijWrp0qV577TVdf/317ksKAABynqtLRfn5+Ro6dGiXhrXhhrZVVVVR7/fII4/ooYce0ubNmzVs2LDESwsAAHKa60tFNTU1mj59uoYNG6bhw4dr+fLlCgaDmjFjhiRp2rRpKi0t1ZIlSyRJ//Ef/6GFCxdqzZo1qqioaG8L85nPfEaf+cxnPHwqAAAg27kOLhMnTtSxY8e0cOFCNTY2asiQIdq8eXN7g92DBw+qV6+Oipxf/OIXam1t1YQJE7o8Tm1trR588MHkSg8AAHJKQo1zZ8+erdmzZ0f8X319fZe/Dxw4kMgmAAAAemCuIgAAYA2CCwAAsAbBBQAAWIPgAgAArEFwAQAA1iC4AAAAaxBcAACANQguAADAGgQXAABgDYILAACwBsEFAABYg+ACAACsQXABAADWILgAAABrEFwAAIA1CC4AAMAaBBcAAGANggsAALAGwQUAAFiD4AIAAKxBcAEAANYguAAAAGsQXAAAgDUILgAAwBoEFwAAYA2CCwAAsAbBBQAAWIPgAgAArEFwAQAA1iC4AAAAaxBcAACANQguAADAGgQXAABgDYILAACwBsEFAABYg+ACAACsQXABAADWILgAAABrEFwAAIA1CC4AAMAaBBcAAGANggsAALAGwQUAAFiD4AIAAKxBcAEAANYguAAAAGsQXAAAgDUILgAAwBoEFwAAYA2CCwAAsAbBBQAAWIPgAgAArEFwAQAA1iC4AAAAaxBcAACANQguAADAGgQXAABgDYILAACwBsEFAABYg+ACAACsQXABAADWILgAAABrEFwAAIA1EgouK1asUEVFhQoLC1VZWant27fHXH/Dhg265pprVFhYqOuuu06bNm1KqLAAACC3uQ4u69atU01NjWpra7Vz504NHjxYo0eP1tGjRyOu/9Zbb2nSpEn69re/rV27dmncuHEaN26c/vznPyddeAAAkFsCxhjj5g6VlZX6u7/7Oz3++OOSpLNnz6q8vFz/+q//qrlz5/ZYf+LEiQoGg3r55Zfbl/393/+9hgwZopUrV0bcRktLi1paWtr/PnXqlC6//HIdOnRIRUVFboqLLBRsDarksRJJ0uHvHVaf/D5pLlF8ccscDEolof/r8GGpjwfPKYnHjFleP8oKICs1NzervLxcJ0+eVN++fb15UONCS0uLycvLMy+88EKX5dOmTTO33357xPuUl5ebn/zkJ12WLVy40Fx//fVRt1NbW2skcePGjRs3btyy4PbXv/7VTdyI6Ty5cPz4cbW1tam4uLjL8uLiYr377rsR79PY2Bhx/cbGxqjbmTdvnmpqatr/PnnypD772c/q4MGD3iU2JCScnqn9Sj/2ReZgX2QW9kfmCF8xueSSSzx7TFfBJVUKCgpUUFDQY3nfvn15E2aIoqIi9kWGYF9kDvZFZmF/ZI5evbzrxOzqkfr166e8vDw1NTV1Wd7U1KQBAwZEvM+AAQNcrQ8AABCNq+CSn5+voUOHasuWLe3Lzp49qy1btqiqqirifaqqqrqsL0mvvvpq1PUBAACicX2pqKamRtOnT9ewYcM0fPhwLV++XMFgUDNmzJAkTZs2TaWlpVqyZIkk6d5779XNN9+sxx57TLfddpvWrl2rP/3pT3ryyScdb7OgoEC1tbURLx8htdgXmYN9kTnYF5mF/ZE5/NgXrrtDS9Ljjz+uH//4x2psbNSQIUP0s5/9TJWVlZKkW265RRUVFXrmmWfa19+wYYMWLFigAwcO6KqrrtIjjzyiW2+91bMnAQAAckNCwQUAACAdmKsIAABYg+ACAACsQXABAADWILgAAABrZExwWbFihSoqKlRYWKjKykpt37495vobNmzQNddco8LCQl133XXatGlTikqa/dzsi6eeekojR47UxRdfrIsvvljV1dVx9x2cc/u5CFu7dq0CgYDGjRvnbwFziNt9cfLkSc2aNUsDBw5UQUGBrr76ao5THnG7L5YvX64vfOELuuCCC1ReXq45c+bo008/TVFps9frr7+uMWPGqKSkRIFAQC+++GLc+9TX1+vLX/6yCgoK9PnPf75LD2THPJv1KAlr1641+fn5ZtWqVeYvf/mLmTlzprnoootMU1NTxPXffPNNk5eXZx555BGzZ88es2DBAnP++eebt99+O8Ulzz5u98XkyZPNihUrzK5du8w777xjvvWtb5m+ffuaDz74IMUlzz5u90XY/v37TWlpqRk5cqQZO3Zsagqb5dzui5aWFjNs2DBz6623mj/84Q9m//79pr6+3uzevTvFJc8+bvfF6tWrTUFBgVm9erXZv3+/eeWVV8zAgQPNnDlzUlzy7LNp0yYzf/58U1dXZyT1mIC5u3379pnevXubmpoas2fPHvPzn//c5OXlmc2bN7vabkYEl+HDh5tZs2a1/93W1mZKSkrMkiVLIq5/xx13mNtuu63LssrKSvOd73zH13LmArf7orszZ86YCy+80Pz617/2q4g5I5F9cebMGXPjjTeap59+2kyfPp3g4hG3++IXv/iFueKKK0xra2uqipgz3O6LWbNmma9+9atdltXU1JgRI0b4Ws5c4yS4/OAHPzBf/OIXuyybOHGiGT16tKttpf1SUWtrq3bs2KHq6ur2Zb169VJ1dbW2bdsW8T7btm3rsr4kjR49Our6cCaRfdHdxx9/rNOnT3s6E2guSnRf/Pu//7suu+wyffvb305FMXNCIvvipZdeUlVVlWbNmqXi4mJ96Utf0uLFi9XW1paqYmelRPbFjTfeqB07drRfTtq3b582bdrEIKhp4NW5O+2zQx8/flxtbW0qLi7usry4uFjvvvtuxPs0NjZGXL+xsdG3cuaCRPZFd/fff79KSkp6vDnhTiL74g9/+IN++ctfavfu3SkoYe5IZF/s27dPv//97zVlyhRt2rRJe/fu1T333KPTp0+rtrY2FcXOSonsi8mTJ+v48eP6yle+ImOMzpw5o7vvvls//OEPU1FkdBLt3N3c3KxPPvlEF1xwgaPHSXuNC7LH0qVLtXbtWr3wwgsqLCxMd3FyyocffqipU6fqqaeeUr9+/dJdnJx39uxZXXbZZXryySc1dOhQTZw4UfPnz9fKlSvTXbScU19fr8WLF+uJJ57Qzp07VVdXp40bN+qhhx5Kd9GQoLTXuPTr1095eXlqamrqsrypqUkDBgyIeJ8BAwa4Wh/OJLIvwh599FEtXbpUr732mq6//no/i5kT3O6Lv/71rzpw4IDGjBnTvuzs2bOSpPPOO0/vvfeerrzySn8LnaUS+VwMHDhQ559/vvLy8tqXXXvttWpsbFRra6vy8/N9LXO2SmRfPPDAA5o6daruvPNOSdJ1112nYDCou+66S/Pnz1evXnx/T5Vo5+6ioiLHtS1SBtS45Ofna+jQodqyZUv7srNnz2rLli2qqqqKeJ+qqqou60vSq6++GnV9OJPIvpCkRx55RA899JA2b96sYcOGpaKoWc/tvrjmmmv09ttva/fu3e2322+/XaNGjdLu3btVXl6eyuJnlUQ+FyNGjNDevXvbw6Mkvf/++xo4cCChJQmJ7IuPP/64RzgJB0rDVH0p5dm52127YX+sXbvWFBQUmGeeecbs2bPH3HXXXeaiiy4yjY2Nxhhjpk6daubOndu+/ptvvmnOO+888+ijj5p33nnH1NbW0h3aI273xdKlS01+fr55/vnnzZEjR9pvH374YbqeQtZwuy+6o1eRd9zui4MHD5oLL7zQzJ4927z33nvm5ZdfNpdddpn50Y9+lK6nkDXc7ova2lpz4YUXmueee87s27fP/Pd//7e58sorzR133JGup5A1PvzwQ7Nr1y6za9cuI8ksW7bM7Nq1y/zP//yPMcaYuXPnmqlTp7avH+4O/f3vf9+88847ZsWKFfZ2hzbGmJ///Ofm8ssvN/n5+Wb48OHmj3/8Y/v/br75ZjN9+vQu669fv95cffXVJj8/33zxi180GzduTHGJs5ebffHZz37WSOpxq62tTX3Bs5Dbz0VnBBdvud0Xb731lqmsrDQFBQXmiiuuMA8//LA5c+ZMikudndzsi9OnT5sHH3zQXHnllaawsNCUl5ebe+65x/zv//5v6gueZbZu3Rrx+B9+/adPn25uvvnmHvcZMmSIyc/PN1dccYX51a9+5Xq7AWOoKwMAAHZIexsXAAAApwguAADAGgQXAABgDYILAACwBsEFAABYg+ACAACsQXABAADWILgAAABrEFwAAIA1CC4AAMAaBBcAAGCN/w8N0gD4izz9WQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evt = 4\n",
    "x = np.zeros(time_samples)\n",
    "for i in range(time_samples):\n",
    "    x[i] = i/time_samples\n",
    "y = test_data[evt]\n",
    "plt.xlim(0, 1), plt.ylim(0, 1)\n",
    "plt.scatter(x, y, color=\"blue\")\n",
    "plt.plot([y_keras[evt][0], y_keras[evt][0]], [0.0, 1.0], color=\"red\")\n",
    "plt.plot([y_keras[evt][0]-y_keras[evt][1], y_keras[evt][0]-y_keras[evt][1]], [0.0, 1.0], color=\"red\")\n",
    "plt.plot([y_keras[evt][0]+y_keras[evt][1], y_keras[evt][0]+y_keras[evt][1]], [0.0, 1.0], color=\"red\")\n",
    "plt.plot([0.0, 1.0], [y_keras[evt][2]+y_keras[evt][3], y_keras[evt][2]+y_keras[evt][3]], color=\"red\")\n",
    "plt.plot([0.0, 1.0], [y_keras[evt][3], y_keras[evt][3]], color=\"red\")\n",
    "plt.plot([test_truth[evt][0], test_truth[evt][0]], [0.0, 1.0], color=\"green\")\n",
    "plt.plot([test_truth[evt][0]-test_truth[evt][1], test_truth[evt][0]-test_truth[evt][1]], [0.0, 1.0], color=\"green\")\n",
    "plt.plot([test_truth[evt][0]+test_truth[evt][1], test_truth[evt][0]+test_truth[evt][1]], [0.0, 1.0], color=\"green\")\n",
    "plt.plot([0.0, 1.0], [test_truth[evt][2]+test_truth[evt][3], test_truth[evt][2]+test_truth[evt][3]], color=\"green\")\n",
    "plt.plot([0.0, 1.0], [test_truth[evt][3], test_truth[evt][3]], color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a9cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_keras_sig = y_keras[ (test_truth >= 0) ]\n",
    "#y_keras_bkg = y_keras[ (test_truth < 1) ]\n",
    "#plt.figure(figsize=(6,6))\n",
    "#plt.hist(y_keras_bkg,log=True,bins=50,label='label == 0',alpha=0.5,color='blue')\n",
    "#plt.hist(y_keras_sig,log=True,bins=50,label='label == 1',alpha=0.5,color='red')\n",
    "#plt.legend().get_frame().set_alpha(0)\n",
    "#plt.xlabel('y_keras')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5074a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
