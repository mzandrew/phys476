{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcc5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostly pulled from hls4ml_3.ipynb and waveform_demo.ipynb\n",
    "# last updated 2025-05-05 by mza\n",
    "name = \"mza_try6\"\n",
    "num_epochs = 10000\n",
    "batch_size = 1000\n",
    "hidden_nodes = [ 64 ]\n",
    "hidden_node_type = \"relu\"\n",
    "truths_to_use = [ 0 ] # t_peak, t_sigma, height, pedestal\n",
    "use_pruning = False\n",
    "prune_ratio = 0.1\n",
    "train = True\n",
    "synth_hls = True\n",
    "integer_part = 1\n",
    "input_quantization = 9\n",
    "inner_quantization = 9\n",
    "output_quantization = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896e5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, errno\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "import numpy as np\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    os.mkdir(name)\n",
    "except OSError as exception:\n",
    "    if exception.errno != errno.EEXIST:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7a50c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_waveforms: 20000\n",
      "num_truths_to_use: 1\n",
      "train_data.shape: (16000, 100)\n",
      "train_truth.shape: (16000, 1)\n",
      "test_data.shape: (4000, 100)\n",
      "test_truth.shape: (4000, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = np.load('waveform_data_0.npy') # (10000, 104)\n",
    "dataset2 = np.load('waveform_data_1.npy') # (10000, 104)\n",
    "dataset = np.concatenate((dataset1, dataset2))\n",
    "num_waveforms = len(dataset)\n",
    "training_quantity = int(0.8 * num_waveforms)\n",
    "num_truths = 4\n",
    "time_samples = len(dataset[0]) - num_truths\n",
    "print(\"num_waveforms: \" + str(num_waveforms))\n",
    "num_truths_to_use = len(truths_to_use)\n",
    "print(\"num_truths_to_use: \" + str(num_truths_to_use))\n",
    "waveforms = dataset[:,num_truths:]\n",
    "truths = dataset[:,:num_truths]\n",
    "waveform_min = min([ min(waveforms[i]) for i in range(len(waveforms)) ])\n",
    "waveform_max = max([ max(waveforms[i]) for i in range(len(waveforms)) ])\n",
    "offset = waveform_min\n",
    "gain = 1.0 / (waveform_max - waveform_min)\n",
    "scaled_waveforms = np.array([ [ gain * (waveforms[j,i] - offset) for i in range(time_samples) ] for j in range(num_waveforms) ])\n",
    "scaled_truths = np.array([ [ truths[j,0]/time_samples, truths[j,1]/time_samples, gain * (truths[j,2] - offset), gain * (truths[j,3] - offset) ] for j in range(num_waveforms) ])\n",
    "train_data = scaled_waveforms[:training_quantity,:]\n",
    "print(\"train_data.shape: \" + str(train_data.shape))\n",
    "train_truth = scaled_truths[:training_quantity,truths_to_use]\n",
    "print(\"train_truth.shape: \" + str(train_truth.shape))\n",
    "test_data = scaled_waveforms[training_quantity:,:]\n",
    "print(\"test_data.shape: \" + str(test_data.shape))\n",
    "test_truth = scaled_truths[training_quantity:,truths_to_use]\n",
    "print(\"test_truth.shape: \" + str(test_truth.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e482df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evt = 8\n",
    "if 0:\n",
    "    x = np.zeros(time_samples)\n",
    "    for i in range(time_samples):\n",
    "        x[i] = i/time_samples\n",
    "    y = train_data[evt]\n",
    "    plt.xlim(0, 1), plt.ylim(0, 1)\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot([train_truth[evt][0], train_truth[evt][0]], [0.0, 1.0], color=\"green\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4744ddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time position of the peak:  0.6038360595703125\n"
     ]
    }
   ],
   "source": [
    "print(\"time position of the peak: \", train_truth[evt][0]) # The 0th column: mean of the Gaussian peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8115e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras import optimizers\n",
    "from callbacks import all_callbacks\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu, quantized_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004b7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_quantizer = quantized_bits(input_quantization, integer_part, alpha=1)\n",
    "inner_quantizer = quantized_bits(inner_quantization, integer_part, alpha=1)\n",
    "output_quantizer = quantized_bits(output_quantization, integer_part, alpha=1)\n",
    "output_quantization_string = 'ap_fixed<' + str(output_quantization) + ',' + str(integer_part) + '>'\n",
    "if hidden_node_type==\"relu\":\n",
    "    hidden_activations = [ quantized_relu(inner_quantization) for i in range(len(hidden_nodes)) ]\n",
    "else:\n",
    "    hidden_activations = [ quantized_sigmoid(inner_quantization) for i in range(len(hidden_nodes)) ]\n",
    "hidden_names = [ hidden_node_type for i in range(len(hidden_nodes)) ]\n",
    "model = Sequential()\n",
    "model.add(QDense(time_samples, input_shape=(time_samples,), name='input_qdense', kernel_quantizer=input_quantizer, bias_quantizer=input_quantizer, kernel_initializer='glorot_uniform'))\n",
    "model.add(QActivation(activation=quantized_sigmoid(input_quantization), name='input_sigmoid'))\n",
    "for i in range(len(hidden_nodes)):\n",
    "    model.add(QDense(hidden_nodes[i], name=hidden_names[i] + str(i) + \"qdense\", kernel_quantizer=inner_quantizer, bias_quantizer=inner_quantizer, kernel_initializer='glorot_uniform'))\n",
    "    model.add(QActivation(activation=hidden_activations[i], name=hidden_names[i] + str(i) + \"activation\"))\n",
    "model.add(QDense(num_truths_to_use, name='output_qdense', kernel_quantizer=output_quantizer, bias_quantizer=output_quantizer, kernel_initializer='glorot_uniform'))\n",
    "if num_truths_to_use<2:\n",
    "    model.add(Activation(activation='sigmoid', name='output_sigmoid'))\n",
    "else:\n",
    "    model.add(Activation(activation='softmax', name='output_softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "955b80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pruning:\n",
    "    from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "    from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "    # the first argument is the percentage of the weights that will be forced to be 0\n",
    "    pruning_params = {\"pruning_schedule\": pruning_schedule.ConstantSparsity(prune_ratio, begin_step=2000, frequency=100)}\n",
    "    model = prune.prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89858d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    #optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    optimizer = optimizers.SGD(learning_rate=0.1)\n",
    "    #model.compile(optimizer=optimizer, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    model.compile(optimizer=optimizer, loss=['mse'])\n",
    "    if use_pruning:\n",
    "        callbacks = all_callbacks(stop_patience=1000, lr_factor=0.5, lr_patience=10, lr_epsilon=0.000001, lr_cooldown=2, lr_minimum=0.0000001, outputDir=name)\n",
    "        callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "        model.fit(train_data, train_truth, batch_size=batch_size, epochs=num_epochs, validation_split=0.25, shuffle=False, callbacks=callbacks.callbacks, verbose=0)\n",
    "    else:\n",
    "        model.fit(train_data, train_truth, batch_size=batch_size, epochs=num_epochs, validation_split=0.25, shuffle=False, verbose=0)\n",
    "    #loss, acc = model.evaluate(test_data, test_truth, verbose=0)\n",
    "    if use_pruning:\n",
    "        model = strip_pruning(model)\n",
    "    model.save(name + '/KERAS_check_best_model.keras')\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    model = load_model(name + '/KERAS_check_best_model.keras', custom_objects=co) # TypeError: <qkeras.qlayers.QActivation object at 0x774300567100> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c321b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('test_acc: {:.3f}, test_loss: {:.3f}'.format(acc, loss))\n",
    "train_prediction = model.predict(train_data)\n",
    "test_prediction = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f7ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "evt = 5\n",
    "if 0:\n",
    "    print(str(test_prediction[evt]) + \" : \" + str(test_truth[evt]))\n",
    "    x = np.zeros(time_samples)\n",
    "    for i in range(time_samples):\n",
    "        x[i] = i/time_samples\n",
    "    y = test_data[evt]\n",
    "    plt.xlim(0, 1); plt.ylim(0, 1)\n",
    "    plt.scatter(x, y, color=\"blue\")\n",
    "    plt.plot([test_prediction[evt,0], test_prediction[evt,0]], [0.0, 1.0], color=\"red\")\n",
    "    plt.plot([test_truth[evt,0], test_truth[evt,0]], [0.0, 1.0], color=\"green\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ec43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(name + '/Input.dat', 'w') as f:\n",
    "    csv.writer(f, delimiter=' ').writerows(test_data)\n",
    "with open(name + '/Output.dat', 'w') as f:\n",
    "    csv.writer(f, delimiter=' ').writerows(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284dbe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml, plotting\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name', default_reuse_factor=10)\n",
    "config['LayerName']['output_sigmoid']['exp_table_t'] = output_quantization_string\n",
    "config['LayerName']['output_sigmoid']['inv_table_t'] = output_quantization_string\n",
    "config['LayerName']['output_sigmoid']['Precision']   = output_quantization_string\n",
    "plotting.print_dict(config)\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=config, output_dir=name + '/hls4ml_prj', part='xc7z020clg400-1',\n",
    "    input_data_tb = name + \"/Input.dat\", output_data_tb = name + \"/Output.dat\", backend='Vitis', verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb370df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=name + '/hls_model.png')\n",
    "#Image(name + '/hls_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db79707",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367173a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_train_prediction = hls_model.predict(np.ascontiguousarray(train_data))\n",
    "hls_test_prediction = hls_model.predict(np.ascontiguousarray(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "a = 0.25; b = 0.75\n",
    "for i in range(num_truths_to_use):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(12,12))\n",
    "    ax1.hist2d(train_truth[:,i].ravel(), train_prediction[:,i].ravel(),     bins=nbins); ax1.plot([0.0, 1.0], [0.0, 1.0], color=\"red\", alpha=0.5); ax1.set_xlim(a, b); ax1.set_ylim(a, b)\n",
    "    ax2.hist2d(test_truth[:,i].ravel(),  test_prediction[:,i].ravel(),      bins=nbins); ax2.plot([0.0, 1.0], [0.0, 1.0], color=\"red\", alpha=0.5); ax2.set_xlim(a, b); ax2.set_ylim(a, b)\n",
    "    ax3.hist2d(train_truth[:,i].ravel(), hls_train_prediction[:,i].ravel(), bins=nbins); ax3.plot([0.0, 1.0], [0.0, 1.0], color=\"red\", alpha=0.5); ax3.set_xlim(a, b); ax3.set_ylim(a, b)\n",
    "    ax4.hist2d(test_truth[:,i].ravel(),  hls_test_prediction[:,i].ravel(),  bins=nbins); ax4.plot([0.0, 1.0], [0.0, 1.0], color=\"red\", alpha=0.5); ax4.set_xlim(a, b); ax4.set_ylim(a, b)\n",
    "    plt.show()\n",
    "    fig.savefig(name + \"/hist2d.\" + str(truths_to_use[i]) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b75762",
   "metadata": {},
   "outputs": [],
   "source": [
    "if synth_hls:\n",
    "    hls_model.build(synth=True, csim=True, cosim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594110d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if synth_hls:\n",
    "    hls4ml.report.read_vivado_report(name + '/hls4ml_prj') # requires 2083 DSPs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
